# 20230516 Can I Just Talk To My Device?

```
This session is part of our Renesas Virtual Conference. Registration/event page here. We are all familiar with cloud-based natural language recognition, but what can you do to enhance the usability of your products with voice if you are not connected? Join us to get an overview of the Renesas ecosystem around voice UI algorithms that run efficiently on their MCUs ? with resources and cycles left over for your application on the same device. You will also see how their acquisition of RealityAI and their efficient ML can be used to enhance your products. View and attend at https://resources.embeddedcomputing.com/Embedded-Computing-Design/Edge-Voice-User-Interfaces?bmid=ad4b79fe6a51&bmid_type=member
```

## presenters
* Kaushal Vora; Sr. Director Business Acceleration & Global Ecosystem at Renesas
* Vin D’Agostino; Founder/President of D’Agostino Industries, a Renesas Partner
* Rich Nass; Executive Vice-President, Brand Director, Embedded Franchise, OpenSystems Media

## evolution of UIs
![](img00.png)
![](img01.png)
![](img02.png)
* touchless allows to handle the device without having to go there and to manipulate it
## phonemes - language
![](img03.png)
![](img04.png)
* what's it gonna cost me to add AI to my product? it is not the software or hardware; itis the data collection, the analyzis and the training part
* success factors: Definition -> Design -> Deployment
![](img05.png)
* so the language is really everything which is possible: but to a toaster you willl just use an appropriate command set for the product
* but what are appropriate selections of functions and which are not? what is a proper response time? (button: 
![](img06.png)
* VUI (voice UI) approach by Renesas has some advantages: by handling dialects, etc. for the user: no voice training or data collection is needed; just deal with text
* Cyberon voice stack
![](img07.png)
![](img08.png)
![](img09.png)
## summary
* voice enabled AI would have tremendous impact
* must be cloud-independant - much of the stuff has to happen locally
* use intention-based model - instead of being able to handle everything
![](img10.png)

